#!/usr/bin/env python

# pip install langchain-community langchain-google-genai
# https://python.langchain.com/docs/integrations/chat/google_generative_ai

from common import *
from langchain_google_genai import GoogleGenerativeAI
from llm_actor.langchain import Conversation
from llm_actor import Actor, Prolog

# model = "gemini-2.0-flash-lite"
model = "gemini-2.0-flash"
# model = "gemini-1.5-flash-8b"

space = "../llm-actor-spaces/spaces/001"

chat = GoogleGenerativeAI(model=model, temperature=0)
prolog = Prolog("prologs/apprentice-system.1")
conv = Conversation(chat, model=model, prolog=prolog)
act = Actor(conv, space=space)

def ask(q):
    print(q)
    print(act.ask(q))

ask("How long (in lines) is the program in x1.c?")
ask("will the code compile? explain!")
act.print_summary()
